{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics Tables for EMA study\n",
    "\n",
    "John Curtin\n",
    "\n",
    "## Overview\n",
    "\n",
    "## Set up environment"
   ],
   "id": "1410acb0-0b1d-4937-be39-9c7013921c63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.2     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\""
     ]
    }
   ],
   "source": [
    "# handle conflicts\n",
    "options(conflicts.policy = \"depends.ok\")\n",
    "# devtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n",
    "# tidymodels_conflictRules()\n",
    "\n",
    "library(kableExtra, exclude = \"group_rows\")\n",
    "# library(patchwork)\n",
    "# library(ggtext)\n",
    "# library(consort)\n",
    "# library(tidyposterior)\n",
    "library(tidyverse)\n"
   ],
   "id": "ad949254-0b30-41d8-a9a0-33ae743e65c0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make metrics df"
   ],
   "id": "b30ca87b-44ad-416d-9281-92e8cf9a06da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_week <- read_csv(file.path(path_models, \n",
    "                                   \"test_metrics_1week_0_v5_nested.csv\"),\n",
    "                         col_types = cols())\n",
    "metrics_day <- read_csv(file.path(path_models, \n",
    "                                  \"test_metrics_1day_0_v5_nested.csv\"),\n",
    "                        col_types = cols())\n",
    "metrics_hour <- read_csv(file.path(path_models, \n",
    "                                   \"test_metrics_1hour_0_v5_nested.csv\"),\n",
    "                         col_types = cols())\n"
   ],
   "id": "700e55a5-459e-42d8-8832-931a70d4a4ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics <- metrics_week |> \n",
    "  mutate(model = \"Week\") |> \n",
    "  bind_rows(metrics_day |> \n",
    "              mutate(model = \"Day\")) |> \n",
    "  bind_rows(metrics_hour |> \n",
    "              mutate(model = \"Hour\")) |> \n",
    "  group_by(.metric, model) |> \n",
    "  summarize(median = median(.estimate), .groups = \"drop\") |> \n",
    "  pivot_wider(names_from = model, values_from = median) |> \n",
    "  select(.metric, Week, Day, Hour)\n",
    "\n",
    "metrics <- metrics[c(4,5,6, 1, 3, 2),]\n"
   ],
   "id": "5260d41b-bd05-4321-9951-61e97091e2a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n"
      ],
      "text/markdown": [
       "  Metric                      Week   Day    Hour\n",
       "  --------------------------- ------ ------ ------\n",
       "  auROC                       0.89   0.90   0.93\n",
       "  sensitivity                 0.82   0.83   0.86\n",
       "  specificity                 0.82   0.85   0.88\n",
       "  balanced accuracy           0.83   0.83   0.85\n",
       "  positive predictive value   0.63   0.30   0.03\n",
       "  negative predictive value   0.94   0.99   1.00\n",
       "\n",
       "  : Areas under the receiver operating characteristic curves (auROCs)\n",
       "  summarize the model's sensitivity and specificity over all possible\n",
       "  decision thresholds. Sensitivity, specificity, balanced accuracy,\n",
       "  positive predictive value, and negative predictive value are\n",
       "  performance metrics calculated at a single decision threshold for each\n",
       "  model determined with Youden's index. All metrics represent median\n",
       "  values across 30 held-out test sets.\n"
      ]
     }
    }
   ],
   "source": [
    "\n",
    "metrics |> \n",
    " mutate(.metric = case_when(.metric == \"roc_auc\" ~ \"auROC\",\n",
    "                            .metric == \"sens\" ~ \"sensitivity\",\n",
    "                            .metric == \"spec\" ~ \"specificity\",\n",
    "                            .metric == \"bal_accuracy\" ~ \"balanced accuracy\",\n",
    "                            .metric == \"ppv\" ~ \"positive predictive value\",\n",
    "                            .metric == \"npv\" ~ \"negative predictive value\")) |> \n",
    " kbl(col.names = c(\"Metric\", \"Week\", \"Day\", \"Hour\"),\n",
    "     booktabs = TRUE,\n",
    "     digits = 2,\n",
    "     align = c(\"l\", \"l\", \"l\", \"l\"),\n",
    "     linesep = \"\",\n",
    "     caption = \"Performance Metrics for Full models by Prediction Window\") |>  \n",
    "  kable_styling(position = \"left\", latex_options = c(\"HOLD_position\")) |>  \n",
    "  column_spec(column = 1, width = \"25em\")  \n"
   ],
   "id": "8dd35878-fe0a-4cbf-b437-4ed4f468d374"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n"
      ],
      "text/markdown": [
       "                       Week   Day   Hour\n",
       "  ------------------- ------ ----- ------\n",
       "                auROC  0.89        \n",
       "          sensitivity  0.82        \n",
       "          specificity  0.82        \n",
       "    balanced accuracy  0.83        \n"
      ]
     }
    }
   ],
   "source": [
    "metrics |> \n",
    "  slice(1:4) |> \n",
    "  mutate(Day = \"\", Hour = \"\") |> \n",
    "  mutate(.metric = case_when(.metric == \"roc_auc\" ~ \"auROC\",\n",
    "                        .metric == \"sens\" ~ \"sensitivity\",\n",
    "                        .metric == \"spec\" ~ \"specificity\",\n",
    "                        .metric == \"bal_accuracy\" ~ \"balanced accuracy\")) |> \n",
    "  kbl(col.names = c(\"\", \"Week\", \"Day\", \"Hour\"),\n",
    "    digits = 2,\n",
    "    align = c(\"r\", \"c\", \"c\", \"c\"),\n",
    "    linesep = \"\") |> \n",
    "  row_spec(row = 0, align = \"c\") |> \n",
    "  kable_styling(full_width = FALSE) |> \n",
    "  kable_classic(\"striped\") |> \n",
    "  column_spec(2, color  = \"red\", bold = TRUE)\n"
   ],
   "id": "8dbb3e63-1802-4cf4-8859-7e5da47b77e4"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
