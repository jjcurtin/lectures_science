{
  "hash": "38287eeefa3ca28721fb948e0a399cf7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Performance Metrics Tables for EMA study\"\nauthor: \"John Curtin\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Overview\n\n\n\n## Set up environment\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\n# devtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n# tidymodels_conflictRules()\n\nlibrary(kableExtra, exclude = \"group_rows\")\n# library(patchwork)\n# library(ggtext)\n# library(consort)\n# library(tidyposterior)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# library(tidymodels)\n\n# Paths\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\npath_models <- format_path(\"studydata/risk/models/ema\")\npath_data_shared <- format_path(\"studydata/risk/data_processed/shared\")\npath_data_ema <- format_path(\"studydata/risk/data_processed/ema\")\n```\n:::\n\n\n## Make metrics df\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmetrics_week <- read_csv(file.path(path_models, \n                                   \"test_metrics_1week_0_v5_nested.csv\"),\n                         col_types = cols())\nmetrics_day <- read_csv(file.path(path_models, \n                                  \"test_metrics_1day_0_v5_nested.csv\"),\n                        col_types = cols())\nmetrics_hour <- read_csv(file.path(path_models, \n                                   \"test_metrics_1hour_0_v5_nested.csv\"),\n                         col_types = cols())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: table-paper\n\nmetrics <- metrics_week |> \n  mutate(model = \"Week\") |> \n  bind_rows(metrics_day |> \n              mutate(model = \"Day\")) |> \n  bind_rows(metrics_hour |> \n              mutate(model = \"Hour\")) |> \n  group_by(.metric, model) |> \n  summarize(median = median(.estimate), .groups = \"drop\") |> \n  pivot_wider(names_from = model, values_from = median) |> \n  select(.metric, Week, Day, Hour)\n\nmetrics <- metrics[c(4,5,6, 1, 3, 2),]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: true\n\nfootnote_table_metrics <- \"Areas under the receiver operating characteristic curves (auROCs) summarize the model's sensitivity and specificity over all possible decision thresholds. Sensitivity, specificity, balanced accuracy, positive predictive value, and negative predictive value are performance metrics calculated at a single decision threshold for each model determined with Youden’s index. All metrics represent median values across 30 held-out test sets.\"\n\nmetrics |> \n mutate(.metric = case_when(.metric == \"roc_auc\" ~ \"auROC\",\n                            .metric == \"sens\" ~ \"sensitivity\",\n                            .metric == \"spec\" ~ \"specificity\",\n                            .metric == \"bal_accuracy\" ~ \"balanced accuracy\",\n                            .metric == \"ppv\" ~ \"positive predictive value\",\n                            .metric == \"npv\" ~ \"negative predictive value\")) |> \n kbl(col.names = c(\"Metric\", \"Week\", \"Day\", \"Hour\"),\n     booktabs = TRUE,\n     digits = 3,\n     align = c(\"l\", \"l\", \"l\", \"l\"),\n     linesep = \"\",\n     caption = \"Performance Metrics for Full models by Prediction Window\") |>  \n  kable_styling(position = \"left\", latex_options = c(\"HOLD_position\")) |>  \n  column_spec(column = 1, width = \"25em\") |> \n  kableExtra::footnote(general = c(footnote_table_metrics), threeparttable = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"border-bottom: 0;\">\n<caption>Performance Metrics for Full models by Prediction Window</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:left;\"> Week </th>\n   <th style=\"text-align:left;\"> Day </th>\n   <th style=\"text-align:left;\"> Hour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> auROC </td>\n   <td style=\"text-align:left;\"> 0.891 </td>\n   <td style=\"text-align:left;\"> 0.899 </td>\n   <td style=\"text-align:left;\"> 0.929 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> sensitivity </td>\n   <td style=\"text-align:left;\"> 0.823 </td>\n   <td style=\"text-align:left;\"> 0.828 </td>\n   <td style=\"text-align:left;\"> 0.864 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> specificity </td>\n   <td style=\"text-align:left;\"> 0.819 </td>\n   <td style=\"text-align:left;\"> 0.845 </td>\n   <td style=\"text-align:left;\"> 0.881 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> balanced accuracy </td>\n   <td style=\"text-align:left;\"> 0.828 </td>\n   <td style=\"text-align:left;\"> 0.835 </td>\n   <td style=\"text-align:left;\"> 0.854 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> positive predictive value </td>\n   <td style=\"text-align:left;\"> 0.630 </td>\n   <td style=\"text-align:left;\"> 0.300 </td>\n   <td style=\"text-align:left;\"> 0.025 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> negative predictive value </td>\n   <td style=\"text-align:left;\"> 0.944 </td>\n   <td style=\"text-align:left;\"> 0.988 </td>\n   <td style=\"text-align:left;\"> 0.999 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Areas under the receiver operating characteristic curves (auROCs) summarize the model's sensitivity and specificity over all possible decision thresholds. Sensitivity, specificity, balanced accuracy, positive predictive value, and negative predictive value are performance metrics calculated at a single decision threshold for each model determined with Youden’s index. All metrics represent median values across 30 held-out test sets.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# \n# \n# metrics_subset <- metrics |> \n#   mutate(day = NA, hour = NA)\n# metrics_subset[1, 2] <- NA\n# metrics_subset[7, ] <- NA\n# \n# metrics_subset |>\n#  kbl(format = \"html\", col.names = c(\"\", \"Week\", \"Day\", \"Hour\"),\n#       digits = 2,\n#       align = c(\"r\", \"c\", \"c\", \"c\"),\n#      linesep = \"\") |> \n#   row_spec(row = 0, align = \"c\") |> \n#   kable_styling(full_width = FALSE) |> \n#   kable_classic(\"striped\") |> \n#   column_spec(2, color  = \"red\", bold = TRUE)\n```\n:::\n",
    "supporting": [
      "ema_tables_metrics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}