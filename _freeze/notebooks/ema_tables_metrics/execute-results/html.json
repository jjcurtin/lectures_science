{
  "hash": "bc0ca6ecac848fe2cc59ddd28e34cbce",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Performance Metrics Tables for EMA study\"\nauthor: \"John Curtin\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n## Overview\n\n\n\n## Set up environment\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\n# devtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n# tidymodels_conflictRules()\n\nlibrary(kableExtra, exclude = \"group_rows\")\n# library(patchwork)\n# library(ggtext)\n# library(consort)\n# library(tidyposterior)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# library(tidymodels)\n\n# Paths\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\npath_models <- format_path(\"studydata/risk/models/ema\")\npath_data_shared <- format_path(\"studydata/risk/data_processed/shared\")\npath_data_ema <- format_path(\"studydata/risk/data_processed/ema\")\n\n# Table format\noptions(knitr.kable.NA = '')\n```\n:::\n\n\n## Make metrics df\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmetrics_week <- read_csv(file.path(path_models, \n                                   \"test_metrics_1week_0_v5_nested.csv\"),\n                         col_types = cols())\nmetrics_day <- read_csv(file.path(path_models, \n                                  \"test_metrics_1day_0_v5_nested.csv\"),\n                        col_types = cols())\nmetrics_hour <- read_csv(file.path(path_models, \n                                   \"test_metrics_1hour_0_v5_nested.csv\"),\n                         col_types = cols())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmetrics <- metrics_week |> \n  mutate(model = \"Week\") |> \n  bind_rows(metrics_day |> \n              mutate(model = \"Day\")) |> \n  bind_rows(metrics_hour |> \n              mutate(model = \"Hour\")) |> \n  group_by(.metric, model) |> \n  summarize(median = median(.estimate), .groups = \"drop\") |> \n  pivot_wider(names_from = model, values_from = median) |> \n  select(.metric, Week, Day, Hour)\n\nmetrics <- metrics[c(4,5,6, 1, 3, 2),]\n```\n:::\n\n::: {.cell tbl-cap='Areas under the receiver operating characteristic curves (auROCs) summarize the model\\'s sensitivity and specificity over all possible decision thresholds. Sensitivity, specificity, balanced accuracy, positive predictive value, and negative predictive value are performance metrics calculated at a single decision threshold for each model determined with Youden’s index. All metrics represent median values across 30 held-out test sets.'}\n\n```{.r .cell-code .hidden}\n#| label: table-paper\n#| tbl-cap: \"Areas under the receiver operating characteristic curves (auROCs) summarize the model's sensitivity and specificity over all possible decision thresholds. Sensitivity, specificity, balanced accuracy, positive predictive value, and negative predictive value are performance metrics calculated at a single decision threshold for each model determined with Youden’s index. All metrics represent median values across 30 held-out test sets.\"\n\nmetrics |> \n mutate(.metric = case_when(.metric == \"roc_auc\" ~ \"auROC\",\n                            .metric == \"sens\" ~ \"sensitivity\",\n                            .metric == \"spec\" ~ \"specificity\",\n                            .metric == \"bal_accuracy\" ~ \"balanced accuracy\",\n                            .metric == \"ppv\" ~ \"positive predictive value\",\n                            .metric == \"npv\" ~ \"negative predictive value\")) |> \n kbl(col.names = c(\"Metric\", \"Week\", \"Day\", \"Hour\"),\n     booktabs = TRUE,\n     digits = 2,\n     align = c(\"l\", \"l\", \"l\", \"l\"),\n     linesep = \"\",\n     caption = \"Performance Metrics for Full models by Prediction Window\") |>  \n  kable_styling(position = \"left\", latex_options = c(\"HOLD_position\")) |>  \n  column_spec(column = 1, width = \"25em\")  \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"\">\n<caption>Performance Metrics for Full models by Prediction Window</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Metric </th>\n   <th style=\"text-align:left;\"> Week </th>\n   <th style=\"text-align:left;\"> Day </th>\n   <th style=\"text-align:left;\"> Hour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> auROC </td>\n   <td style=\"text-align:left;\"> 0.89 </td>\n   <td style=\"text-align:left;\"> 0.90 </td>\n   <td style=\"text-align:left;\"> 0.93 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> sensitivity </td>\n   <td style=\"text-align:left;\"> 0.82 </td>\n   <td style=\"text-align:left;\"> 0.83 </td>\n   <td style=\"text-align:left;\"> 0.86 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> specificity </td>\n   <td style=\"text-align:left;\"> 0.82 </td>\n   <td style=\"text-align:left;\"> 0.85 </td>\n   <td style=\"text-align:left;\"> 0.88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> balanced accuracy </td>\n   <td style=\"text-align:left;\"> 0.83 </td>\n   <td style=\"text-align:left;\"> 0.83 </td>\n   <td style=\"text-align:left;\"> 0.85 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> positive predictive value </td>\n   <td style=\"text-align:left;\"> 0.63 </td>\n   <td style=\"text-align:left;\"> 0.30 </td>\n   <td style=\"text-align:left;\"> 0.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 25em; \"> negative predictive value </td>\n   <td style=\"text-align:left;\"> 0.94 </td>\n   <td style=\"text-align:left;\"> 0.99 </td>\n   <td style=\"text-align:left;\"> 1.00 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code .hidden}\n#| label: table-paper\n#| tbl-cap: \"Areas under the receiver operating characteristic curves (auROCs) summarize the model's sensitivity and specificity over all possible decision thresholds. Sensitivity, specificity, balanced accuracy, positive predictive value, and negative predictive value are performance metrics calculated at a single decision threshold for each model determined with Youden’s index. All metrics represent median values across 30 held-out test sets.\"\n\n  # kableExtra::footnote(general = c(footnote_table_metrics), threeparttable = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: table-metrics-week_only\nmetrics |> \n  slice(1:4) |> \n  mutate(Day = \"\", Hour = \"\") |> \n  mutate(.metric = case_when(.metric == \"roc_auc\" ~ \"auROC\",\n                        .metric == \"sens\" ~ \"sensitivity\",\n                        .metric == \"spec\" ~ \"specificity\",\n                        .metric == \"bal_accuracy\" ~ \"balanced accuracy\")) |> \n  kbl(col.names = c(\"\", \"Week\", \"Day\", \"Hour\"),\n    digits = 2,\n    align = c(\"r\", \"c\", \"c\", \"c\"),\n    linesep = \"\") |> \n  row_spec(row = 0, align = \"c\") |> \n  kable_styling(full_width = FALSE) |> \n  kable_classic(\"striped\") |> \n  column_spec(2, color  = \"red\", bold = TRUE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table lightable-classic lightable-striped\" style='width: auto !important; margin-left: auto; margin-right: auto; font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:right;text-align: center;\">  </th>\n   <th style=\"text-align:center;text-align: center;\"> Week </th>\n   <th style=\"text-align:center;text-align: center;\"> Day </th>\n   <th style=\"text-align:center;text-align: center;\"> Hour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> auROC </td>\n   <td style=\"text-align:center;font-weight: bold;color: red !important;\"> 0.89 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> sensitivity </td>\n   <td style=\"text-align:center;font-weight: bold;color: red !important;\"> 0.82 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> specificity </td>\n   <td style=\"text-align:center;font-weight: bold;color: red !important;\"> 0.82 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> balanced accuracy </td>\n   <td style=\"text-align:center;font-weight: bold;color: red !important;\"> 0.83 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "ema_tables_metrics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}